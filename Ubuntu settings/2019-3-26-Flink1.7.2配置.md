# Flink1.7.2配置

>  Flink 有两种部署的模式，分别是 Standalone 以及 Yarn Cluster 模式。
>
> -  Standalone模式：Flink 必须依赖于 Zookeeper 来实现 JobManager 的 HA（Zookeeper 已经成为了大部分开源框架 HA 必不可少的模块）。在 Zookeeper 的帮助下，一个 Standalone 的 Flink 集群会同时有多个活着的 JobManager，其中只有一个处于工作状态，其他处于 Standby 状态。当工作中的 JobManager 失去连接后（如宕机或 Crash），Zookeeper 会从 Standby 中选举新的 JobManager 来接管 Flink 集群。
>
> - Yarn Cluaster 模式：Flink 就要依靠 Yarn 本身来对 JobManager 做 HA 了。其实这里完全是 Yarn 的机制。对于 Yarn Cluster 模式来说，JobManager 和 TaskManager 都是被 Yarn 启动在 Yarn 的 Container 中。此时的 JobManager，其实应该称之为 Flink Application Master。也就说它的故障恢复，就完全依靠着 Yarn 中的 ResourceManager（和 MapReduce 的 AppMaster 一样）。由于完全依赖了 Yarn，因此不同版本的 Yarn 可能会有细微的差异。这里不再做深究。

下面采用standalone配置

第一步，创建目录`/usr/local/flink`，解压压缩包到`/usr/local/flink`目录下，并分配用户权限：

```shell
sudo tar -zxvf flink-1.7.2-bin-hadoop26-scala_2.12.tgz -C /usr/local/flink
cd /usr/local
sudo chown -R konfuse flink/
```

第二步，加入环境变量，在`/etc/profile`文件中加入flink的PATH：

```shell
# set flink environment
export FLINK_HOME=/usr/local/flink/flink-1.7.2
export PATH=$PATH:$FLINK_HOME/bin
```

​	刷新当前环境，或重启计算机：

```shell
source /etc/profile
```

第三步，在目录`/usr/local/flink/conf/`修改配置文件`masters`，`slaves`，`flink-conf.yaml`，并同步给所有的节点：

## 1. `masters`配置

vim打开文件，加入：

```shell
master:8081
```

## 2. `slaves`配置

vim打开文件，加入：

```shell
slaver1
slaver2
```

## 3. `flink-conf.yaml`配置

vim打开文件，修改：

```shell
# JobManager runs.
jobmanager.rpc.address: master

# The RPC port where the JobManager is reachable.
jobmanager.rpc.port: 6123


# The heap size for the JobManager JVM
jobmanager.heap.size: 1024m


# The heap size for the TaskManager JVM
taskmanager.heap.size: 2048m


# The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.
taskmanager.numberOfTaskSlots: 8

# The parallelism used for programs that did not specify and other parallelism.
parallelism.default: 1

...
...

# The port under which the web-based runtime monitor listens.
# A value of -1 deactivates the web server
rest.port: 8081
```

## 4. 启动flink

```shell
start-cluster.sh
```