# Hadoop2.6 环境配置

> Hadoop的配置需要依赖于Java环境

首先解压Hadoop文件到`/usr/local/`目录下

```shell
sudo tar -zxvf hadoop-2.6.5.tar.gz -C /usr/local
```

重命名并修改权限：

```shell
cd /usr/local
sudo mv ./hadoop-2.6.5/ ./hadoop
sudo chown -R konfuse /hadoop
```

加入环境变量，在`/etc/profile`文件中加入hadoop的PATH：

```shell
# set hadoop environment
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

刷新当前环境，或重启计算机：

```shell
source /etc/profile
```

## 一. 伪分布式配置：

伪分布式需要配置`/usr/local/hadoop/etc/hadoop`下的三个配置文件：

### 1. `hadoop-env.sh`配置

在其中加入计算机当前的Java环境：

```shell
# The java implementation to use.
export JAVA_HOME=/usr/java/jdk1.8.0_201
```

### 2. `core-site.xml`配置

vim打开文件，在`<configuration></configuration>`中添加如下配置：

```xml
<configuration>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/usr/local/hadoop/tmp</value>
        </property>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://localhost:9000</value>
        </property>
</configuration>
```

说明：可以看到这里使用的是`hdfs://localhost:9000`的hdfs文件系统，其它还有淘宝的`tfs://`，谷歌的`gfs://`以及本地的`file://`。

### 3. `hdfs-site.xml`配置

vim打开文件，在`<configuration></configuration>`中添加如下配置：

```xml
<configuration>
        <property>
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
               <name>dfs.namenode.name.dir</name>
               <value>/usr/local/hadoop/tmp/dfs/name</value>
        </property>
        <property>
               <name>dfs.datanode.data.dir</name>
               <value>/usr/local/hadoop/tmp/dfs/data</value>
        </property>
</configuration>
```

其中，`dfs.replication`指的是文件的备份数。

**配置说明：** 

- Hadoop的运行方式由配置文件决定，Hadoop运行时会读取配置文件，因此删除`core-site.xml`中的配置项，就可以从伪分布模式切换到非分布式模式。
- 官方教程中，伪分布式只需要配置`fs.defaultFS`和`dfs.replication`就可以运行，但是默认使用的临时目录为`/tmp/hadoop-hadoop`，而这个目录在重启时有可能被系统清理掉，导致必须重新执行format才行。
- 所以实际使用需要配置`hadoop.tmp.dir`，`dfs.namenode.name.dir`和`dfs.datanode.data.dir`。

配置成功，启动hadoop之前需要对namenode进行初始化：

```shell
hdfs namenode -format
```

然后开启NameNode和DatNode进程：

```shell
start-dfs.sh
```

**注意：** 每次使用`hdfs namenode -format`命令进行初始化时，都会为NameNode生成新的namespaceID，但是在目录`hadoop.tmp.dir`中还是保留上次的namespaceID，若namespaceID不一致，则DataNode无法启动。所以需要删除目录`/usr/local/hadoop/tmp/dfs`下的data，重新生成datanode。

关闭Hadoop：

```shell
stop-dfs.sh
```

## 二. 集群配置：

第一步对IP，Host，ssh进行配置，使集群之间可以互相通讯。可以在master进行修改，完成之后备份到其它机器上。

第二步修改Hadoop的配置文件，满足集群环境要求。

### 1. 集群网络配置

- 修改主机名，把三台虚拟机分别命名为：<br>主节点：master <br>从节点1：slaver1 <br>从节点2：slaver2：

  ```shell
  sudo vim /etc/hostname
  ```

- 接下来打开hosts文件，将三台虚拟机的ip地址和主机名追加在里面：

  ```shell
  sudo vim /etc/hosts
  
  192.168.92.138	master
  192.168.92.139	slaver1
  192.168.92.140	slaver2
  ```

  三台虚拟机的hosts文件一样，配置完成之后可以互相通讯。

- 配置三台虚拟机的ssh，并设置免密登录，首先完成安装openssh-server包：

  ```shell
  sudo apt install openssh-server
  ```

### 2. Hadoop配置

集群的配置主要涉及对`/usr/local/hadoop/etc/hadoop`下六个文件的修改：

#### 1. `hadoop-env.sh`配置

在其中加入计算机当前的Java环境：

```shell
# The java implementation to use.
export JAVA_HOME=/usr/java/jdk1.8.0_201
# The hadoop configuration to use.
export HADOOP_CONF_DIR=/home/hadoop/hadoop-2.7.7/etc/hadoop
```

#### 2. `core-site.xml`配置

vim打开文件，在`<configuration></configuration>`中添加如下配置：

```xml
<configuration>
	<!--1.A base for other temporary directories.-->
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/usr/local/hadoop/tmp</value>
	</property>
    <!--2.the default file system-->
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://master:9000</value>
	</property>
</configuration>
```

#### 3. `hdfs-site.xml`配置

vim打开文件，在`<configuration></configuration>`中添加如下配置：

```xml
<configuration>
	<!--1.where the DFS name node should store the name table(fsimage)-->
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/usr/local/hadoop/tmp/dfs/name</value>
	</property>
	<!--2.where an DFS data node should store its blocks.-->
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/usr/local/hadoop/tmp/dfs/data</value>
	</property>
	<!--3.Default block replication.-->
	<property>
		<name>dfs.replication</name>
		<value>2</value>
	</property>
	<!--4.enable permission checking in HDFS-->
	<property>
		<name>dfs.permissions</name>
		<value>false</value>
	</property>
</configuration>
```

#### 4. `mapred-site.xml`配置

文件本身不存在，从`mapred-site.xml.template`文件复制新文件为`mapred-site.xml`，然后vim打开，在`<configuration></configuration>`中添加如下配置：

```xml
<configuration>
	<!--1.The runtime framework for executing MapReduce jobs.-->
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
	<!--2.MapReduce JobHistory Server IPC host:port-->
	<property>
		<name>mapreduce.jobhistory.address</name>
		<value>master:10020</value>
	</property>
	<!--3.MapReduce JobHistory Server Web UI host:port-->
	<property>
		<name>mapreduce.jobhistory.webapp.address</name>
		<value>master:19888</value>
	</property>
</configuration>
```

#### 5. `yarn-site.xml`配置

vim打开文件，在`<configuration></configuration>`中添加如下配置：

```xml
<configuration>
	<!--0.A comma separated list of services...-->
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
	</property>
	<!--1.The address of the applications manager interface in the RM.-->
	<property>
		<name>yarn.resourcemanager.address</name>
		<value>master:8032</value>
	</property>
	<!--2.The address of the scheduler interface.-->
	<property>
		<name>yarn.resourcemanager.scheduler.address</name>
		<value>master:8030</value>
	</property>
	<!--3.resource-tracker-->
	<property>	
		<name>yarn.resourcemanager.resource-tracker.address</name>	
		<value>master:8031</value>	
	</property>	
	<!--4.The address of the RM admin interface.-->
	<property>
		<name>yarn.resourcemanager.admin.address</name>
		<value>master:8033</value>
	</property>
	<!--5.The http address of the RM web application.-->
	<property>
		<name>yarn.resourcemanager.webapp.address</name>
		<value>master:8088</value>
	</property>	
	<!--6.Whether to enable log aggregation-->
	<property>
		<name>yarn.log-aggregation-enable</name>
		<value>true</value>
	</property>	
</configuration>
```

#### 6. `slaves`配置

打开`slaves`文件，在其中加入两台从主机的名字：

```
slaver1
slaver2
```

